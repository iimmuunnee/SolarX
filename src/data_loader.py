import pandas as pd
import numpy as np
import os
from sklearn.preprocessing import MinMaxScaler

class SolarDataManager:
    def __init__(self):
        # ìŠ¤ì¼€ì¼ëŸ¬ ì •ì˜
        self.scaler_x = MinMaxScaler()
        self.scaler_y = MinMaxScaler()
        
    def load_and_split_standard(self, data_dir='./data', split_ratio=0.8):
        """
        [ì •ì„ ëª¨ë“œ] Data Leakage ë°©ì§€ ë¡œì§
        1. ì „ì²´ ë°ì´í„° ë¡œë“œ
        2. ì‹œê°„ìˆœ ì •ë ¬
        3. 8:2ë¡œ ë¶„í•  (Train / Test)
        4. ì˜¤ì§ 'Train' ë°ì´í„°ë¡œë§Œ ìŠ¤ì¼€ì¼ëŸ¬ í•™ìŠµ(fit)
        5. Test ë°ì´í„°ëŠ” Trainì˜ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜(transform)ë§Œ ìˆ˜í–‰
        """
        print(f">>> ğŸ“‚ [FM ëª¨ë“œ] '{data_dir}' ë°ì´í„° ë¡œë“œ ë° ì •ì„ ë¶„í•  ì¤‘...")
        
        # 1. íŒŒì¼ ë¡œë“œ ë° ë³‘í•© (ê¸°ì¡´ ë¡œì§ ë™ì¼)
        weather_list = []
        solar_df = None
        
        if not os.path.exists(data_dir):
            raise FileNotFoundError(f"âŒ '{data_dir}' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")

        for filename in os.listdir(data_dir):
            if not filename.endswith('.csv'): continue
            filepath = os.path.join(data_dir, filename)
            try:
                df = pd.read_csv(filepath, encoding='cp949')
            except:
                df = pd.read_csv(filepath, encoding='utf-8')
                
            if 'ê¸°ì˜¨(Â°C)' in df.columns:
                weather_list.append(df)
            elif '01ì‹œ' in df.columns:
                solar_df = df

        if not weather_list or solar_df is None:
            raise ValueError("âŒ ë°ì´í„° íŒŒì¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")

        # ë‚ ì”¨ ë³‘í•©
        weather_df = pd.concat(weather_list, ignore_index=True)
        if 'ì¼ì‹œ' in weather_df.columns:
            weather_df['Datetime'] = pd.to_datetime(weather_df['ì¼ì‹œ'])
        weather_df = weather_df.sort_values('Datetime').reset_index(drop=True)

        # ë°œì „ëŸ‰ ì „ì²˜ë¦¬
        date_col = 'ë‚ ì§œ' if 'ë‚ ì§œ' in solar_df.columns else solar_df.columns[0]
        solar_melted = solar_df.melt(id_vars=[date_col],
                                     value_vars=[f'{i:02d}ì‹œ' for i in range(1, 25)],
                                     var_name='ì‹œê°„_str',
                                     value_name='ë°œì „ëŸ‰')
        solar_melted['Hour'] = solar_melted['ì‹œê°„_str'].str.replace('ì‹œ', '').astype(int) - 1
        solar_melted['Date'] = pd.to_datetime(solar_melted[date_col])
        solar_melted['Datetime'] = solar_melted['Date'] + pd.to_timedelta(solar_melted['Hour'], unit='h')

        # ìµœì¢… ë³‘í•©
        req_cols = ['Datetime', 'ê¸°ì˜¨(Â°C)', 'ê°•ìˆ˜ëŸ‰(mm)', 'í’ì†(m/s)', 'ìŠµë„(%)', 'ì¼ì¡°(hr)', 'ì¼ì‚¬(MJ/m2)', 'ì „ìš´ëŸ‰(10ë¶„ìœ„)']
        for col in req_cols:
            if col not in weather_df.columns: weather_df[col] = 0
        weather_selected = weather_df[req_cols].fillna(0)
        final_data = pd.merge(weather_selected, solar_melted[['Datetime', 'ë°œì „ëŸ‰']], on='Datetime', how='inner')
        final_data = final_data.sort_values('Datetime').reset_index(drop=True)
        
        # =========================================================
        # ğŸ”¥ ì—¬ê¸°ê°€ ì •ì„ì˜ í•µì‹¬ì…ë‹ˆë‹¤!
        # =========================================================
        # 1. ë°ì´í„°ë¥¼ ë¨¼ì € ìë¦…ë‹ˆë‹¤.
        split_idx = int(len(final_data) * split_ratio)
        train_df = final_data.iloc[:split_idx]
        test_df = final_data.iloc[split_idx:]
        
        print(f"âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ: Train({len(train_df)}ê°œ) / Test({len(test_df)}ê°œ)")
        
        feature_cols = ['ê¸°ì˜¨(Â°C)', 'ê°•ìˆ˜ëŸ‰(mm)', 'í’ì†(m/s)', 'ìŠµë„(%)', 'ì¼ì¡°(hr)', 'ì¼ì‚¬(MJ/m2)', 'ì „ìš´ëŸ‰(10ë¶„ìœ„)', 'ë°œì „ëŸ‰']
        label_col = ['ë°œì „ëŸ‰']
        
        # 2. Train ë°ì´í„°ë¡œë§Œ 'ê³µë¶€(fit)' í•©ë‹ˆë‹¤.
        self.scaler_x.fit(train_df[feature_cols])
        self.scaler_y.fit(train_df[label_col])
        
        # 3. ê·¸ ê¸°ì¤€ìœ¼ë¡œ Trainê³¼ Testë¥¼ ë³€í™˜(transform) í•©ë‹ˆë‹¤.
        train_x_scaled = self.scaler_x.transform(train_df[feature_cols])
        train_y_scaled = self.scaler_y.transform(train_df[label_col])
        
        test_x_scaled = self.scaler_x.transform(test_df[feature_cols])
        test_y_scaled = self.scaler_y.transform(test_df[label_col])
        
        return train_x_scaled, train_y_scaled, test_x_scaled, test_y_scaled

    def create_sequences(self, data_x, data_y, seq_length=24):
        """ì‹œê³„ì—´ ìœˆë„ìš° ìƒì„±"""
        xs, ys = [], []
        for i in range(len(data_x) - seq_length):
            x = data_x[i:i+seq_length]
            y = data_y[i+seq_length]
            xs.append(x)
            ys.append(y)
        return np.array(xs), np.array(ys)

    def inverse_transform_y(self, y_scaled):
        return self.scaler_y.inverse_transform(y_scaled)